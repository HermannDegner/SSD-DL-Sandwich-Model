# -*- coding: utf-8 -*-
"""
SSDæ„å‘³ãƒ–ãƒªãƒƒã‚¸ï¼šãƒ©ãƒ™ãƒ«ä»˜ã‘ã‚¨ãƒ³ã‚¸ãƒ³çµ±åˆç‰ˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
â€” DLåŸ‹ã‚è¾¼ã¿ â‡” SSDã‚³ã‚¢é–“ã®æ„å‘³çš„å¤‰æ›å±¤ â€”

ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€SSD-DLã‚µãƒ³ãƒ‰ã‚¤ãƒƒãƒãƒ¢ãƒ‡ãƒ«ã®å¿ƒè‡“éƒ¨ã§ã‚ã‚‹ã€Œæ„å‘³ã®ãƒ–ãƒªãƒƒã‚¸ã€ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
ä¸»ãªæ©Ÿèƒ½ï¼š
1.  äººé–“ã®è¨€èªï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰ã‚’ã€SSDã‚³ã‚¢ãŒç†è§£ã§ãã‚‹å¤šå±¤çš„ãªã€Œæ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ«ã€ã«å¤‰æ›ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼‰ã€‚
2.  SSDã‚³ã‚¢ã®æ€è€ƒçµæœã§ã‚ã‚‹ã€Œåå¿œãƒ™ã‚¯ãƒˆãƒ«ã€ã‚’ã€DLç”Ÿæˆãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ãã‚‹åŸ‹ã‚è¾¼ã¿ã‚„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›ï¼ˆãƒ‡ã‚³ãƒ¼ãƒ‰ï¼‰ã€‚
"""

import numpy as np
import torch
import torch.nn as nn
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, field
from enum import Enum

# å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ©ãƒ™ãƒ«ä»˜ã‘ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from simple_ssd_labeling_engine import SimpleSSDLabelingEngine, SSDLabel, SSLayerType, SSConcept

# --- ãƒ‡ãƒ¼ã‚¿æ§‹é€ å®šç¾© ---

@dataclass
class MeaningPressureVector:
    """SSDã‚³ã‚¢ã¸ã®å…¥åŠ›å½¢å¼ã€‚å››å±¤æ§‹é€ ã«å¯¾å¿œã—ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’æŒã¤ã€‚"""
    physical: np.ndarray    # ç‰©ç†å±¤ã¸ã®æ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ«
    base: np.ndarray        # åŸºå±¤ã¸ã®æ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ«
    core: np.ndarray        # ä¸­æ ¸å±¤ã¸ã®æ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ«
    upper: np.ndarray       # ä¸Šå±¤ã¸ã®æ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ«
    metadata: Dict          # ãƒ©ãƒ™ãƒ«æƒ…å ±ãªã©ã€è¨ˆç®—ä»¥å¤–ã®ä»˜éšãƒ‡ãƒ¼ã‚¿

@dataclass
class ReactionVector:
    """SSDã‚³ã‚¢ã‹ã‚‰ã®å‡ºåŠ›å½¢å¼ã€‚æ€è€ƒçµæœã‚’è¦ç´„ã™ã‚‹ã€‚"""
    concept_activations: np.ndarray     # å„æ¦‚å¿µãƒãƒ¼ãƒ‰ã®æœ€çµ‚çš„ãªæ´»æ€§åº¦
    layer_responses: Dict[str, float]   # å››å±¤ãã‚Œãã‚Œã®åå¿œå¼·åº¦
    emergent_keywords: List[str]        # ã€Œè·³èºã€ã«ã‚ˆã£ã¦ç”Ÿã¾ã‚ŒãŸæ–°ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    confidence: float                   # æ€è€ƒçµæœã«å¯¾ã™ã‚‹å…¨ä½“çš„ãªç¢ºä¿¡åº¦

# --- ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ ---

class SSDBridge:
    """
    SSDæ„å‘³ãƒ–ãƒªãƒƒã‚¸ï¼šDLã®æ¬¡å…ƒç©ºé–“ã¨SSDã®åŠ›å­¦ãƒ¢ãƒ‡ãƒ«ã‚’ç¹‹ãå¤‰æ›å™¨ã€‚
    """
    
    def __init__(self, 
                 embedding_dim: int = 512,
                 concept_nodes: int = 1000,
                 layer_dim: int = 256):
        """
        ãƒ–ãƒªãƒƒã‚¸ã®åˆæœŸåŒ–
        Args:
            embedding_dim (int): DLãƒ¢ãƒ‡ãƒ«ãŒæ‰±ã†åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°
            concept_nodes (int): SSDã‚³ã‚¢ãŒæŒã¤å†…éƒ¨æ¦‚å¿µãƒãƒ¼ãƒ‰ã®æ•°
            layer_dim (int): SSDã®å„å±¤ã‚’è¡¨ç¾ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã®åŸºæœ¬æ¬¡å…ƒæ•°
        """
        self.embedding_dim = embedding_dim
        self.concept_nodes = concept_nodes
        self.layer_dim = layer_dim
        
        # 1. ç°¡æ˜“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ©ãƒ™ãƒ«ä»˜ã‘ã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–
        self.labeler = SimpleSSDLabelingEngine()
        
        # 2. DLåŸ‹ã‚è¾¼ã¿ â†’ SSDæ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ« ã¸ã®å¤‰æ›ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰
        self.dl_to_ssd_net = self._build_dl_to_ssd_bridge()
        
        # 3. SSDåå¿œãƒ™ã‚¯ãƒˆãƒ« â†’ DLç”Ÿæˆç”¨åŸ‹ã‚è¾¼ã¿ ã¸ã®å¤‰æ›ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰
        self.ssd_to_dl_net = self._build_ssd_to_dl_bridge()
        
        # 4. SSDã®ä¸»è¦æ¦‚å¿µãƒ©ãƒ™ãƒ«ã¨ã€å†…éƒ¨ãƒãƒ¼ãƒ‰IDã®ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ã‚’ä½œæˆ
        self.concept_mapping = self._init_concept_mapping()

    # --- ãƒ–ãƒªãƒƒã‚¸ã®æ§‹ç¯‰ ---

    def _build_dl_to_ssd_bridge(self) -> nn.ModuleDict:
        """DLåŸ‹ã‚è¾¼ã¿ â†’ SSDæ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ« å¤‰æ›å™¨ã‚’æ§‹ç¯‰"""
        # å„å±¤ã”ã¨ã«ç•°ãªã‚‹å°„å½±ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ï¼‰ã‚’ç”¨æ„ã™ã‚‹
        # ã“ã‚Œã«ã‚ˆã‚Šã€å˜ä¸€ã®DLåŸ‹ã‚è¾¼ã¿ã‹ã‚‰å¤šå±¤çš„ãªæ„å‘³ã‚’æŠ½å‡ºã™ã‚‹
        return nn.ModuleDict({
            'physical_projector': nn.Sequential(
                nn.Linear(self.embedding_dim, self.layer_dim),
                nn.ReLU(),
                nn.Linear(self.layer_dim, self.layer_dim)
            ),
            'base_projector': nn.Sequential(
                nn.Linear(self.embedding_dim, self.layer_dim * 2),
                nn.ReLU(), 
                nn.Linear(self.layer_dim * 2, self.layer_dim * 2)
            ),
            'core_projector': nn.Sequential(
                nn.Linear(self.embedding_dim, self.layer_dim * 2),
                nn.ReLU(),
                nn.Linear(self.layer_dim * 2, self.layer_dim * 2)
            ),
            'upper_projector': nn.Sequential(
                nn.Linear(self.embedding_dim, self.layer_dim),
                nn.ReLU(),
                nn.Linear(self.layer_dim, self.layer_dim)
            ),
        })

    def _build_ssd_to_dl_bridge(self) -> nn.Module:
        """SSDåå¿œãƒ™ã‚¯ãƒˆãƒ« â†’ DLç”Ÿæˆç”¨åŸ‹ã‚è¾¼ã¿ å¤‰æ›å™¨ã‚’æ§‹ç¯‰"""
        # SSDã®æ€è€ƒçµæœï¼ˆæ¦‚å¿µæ´»æ€§åº¦ï¼‹å±¤ã®åå¿œï¼‰ã‚’ãƒ•ãƒ©ãƒƒãƒˆãªãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦å—ã‘å–ã‚‹
        total_input_dim = self.concept_nodes + len(SSLayerType)
        
        return nn.Sequential(
            nn.Linear(total_input_dim, self.embedding_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(self.embedding_dim * 2, self.embedding_dim),
            nn.LayerNorm(self.embedding_dim) # å‡ºåŠ›ã‚’å®‰å®šåŒ–ã•ã›ã‚‹
        )

    def _init_concept_mapping(self) -> Dict[str, int]:
        """æ¦‚å¿µãƒ©ãƒ™ãƒ« â†’ SSDã‚³ã‚¢ã®ãƒãƒ¼ãƒ‰IDã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’åˆæœŸåŒ–"""
        mapping = {}
        node_id = 0
        
        # SSDã®ä¸»è¦æ¦‚å¿µã‚’å›ºå®šIDã«ãƒãƒƒãƒ”ãƒ³ã‚°
        for concept in SSConcept:
            mapping[concept.value] = node_id
            node_id += 1
            
        # å››å±¤æ§‹é€ ã‚‚ãƒãƒ¼ãƒ‰ã¨ã—ã¦ãƒãƒƒãƒ”ãƒ³ã‚°
        for layer in SSLayerType:
            mapping[f"layer_{layer.value.lower()}"] = node_id
            node_id += 1

        # ä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚‚è¿½åŠ 
        common_keywords = [
            "ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼", "ã‚¹ãƒˆãƒ¬ã‚¹", "è¦æ±‚", "æœŸå¾…", "è² è·",
            "ã†ã¾ãã„ã", "èª¿å’Œ", "ãƒãƒ©ãƒ³ã‚¹", "å®‰å®š", "å¿«é©",
            "é–ƒã", "ã‚¢ã‚¤ãƒ‡ã‚¢", "ç™ºæƒ³", "é©æ–°", "å¤‰é©",
            "é€€å±ˆ", "ã¤ã¾ã‚‰ãªã„", "é£½ããŸ", "ãƒãƒ³ãƒãƒª",
            "æœ¬èƒ½", "æ„Ÿæƒ…", "æ¬²æ±‚", "ãƒ«ãƒ¼ãƒ«", "åˆ¶åº¦",
            "ç†å¿µ", "ä¾¡å€¤è¦³", "ä¿¡å¿µ", "ç‰©èª", "æ„å‘³"
        ]
        
        for keyword in common_keywords:
            if keyword not in mapping:
                mapping[keyword] = node_id
                node_id += 1
                if node_id >= self.concept_nodes: break # ãƒãƒ¼ãƒ‰æ•°ä¸Šé™
        return mapping

    # --- ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰/ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç† ---

    def encode_to_ssd(self, 
                      text: str, 
                      dl_embedding: Optional[torch.Tensor] = None) -> MeaningPressureVector:
        """
        ãƒ†ã‚­ã‚¹ãƒˆ(+DLåŸ‹ã‚è¾¼ã¿)ã‹ã‚‰SSDæ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ«ã¸ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã€‚
        """
        
        # 1. ãƒ©ãƒ™ãƒ«ä»˜ã‘ã‚¨ãƒ³ã‚¸ãƒ³ã§ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰SSDæ¦‚å¿µã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§æŠ½å‡º
        labels = self.labeler.label_text(text)
        
        # 2. æŠ½å‡ºã—ãŸãƒ©ãƒ™ãƒ«ã«åŸºã¥ãã€å„å±¤ã¸ã®åˆæœŸæ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
        layer_pressures = self._labels_to_layer_pressures(labels)
        
        # 3. å¤–éƒ¨DLãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®åŸ‹ã‚è¾¼ã¿ãŒã‚ã‚Œã°ã€ãã‚Œã‚’çµ±åˆã—ã¦æ„å‘³åœ§ã‚’å¼·åŒ–
        if dl_embedding is not None:
            enhanced_pressures = self._integrate_dl_embedding(
                layer_pressures, dl_embedding
            )
        else:
            enhanced_pressures = layer_pressures
            
        # 4. SSDã‚³ã‚¢ã«æ¸¡ã™ãŸã‚ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        metadata = {
            'original_text': text,
            'detected_labels': [
                {
                    'concept': label.concept.value,
                    'layer': label.layer.value, 
                    'confidence': label.confidence,
                    'evidence': label.evidence_text
                }
                for label in labels
            ],
            'layer_activation_summary': {
                layer.value: sum(1 for l in labels if l.layer == layer)
                for layer in SSLayerType
            }
        }
        
        return MeaningPressureVector(
            physical=enhanced_pressures['physical'],
            base=enhanced_pressures['base'],
            core=enhanced_pressures['core'],
            upper=enhanced_pressures['upper'],
            metadata=metadata
        )

    def decode_from_ssd(self, reaction: ReactionVector) -> torch.Tensor:
        """
        SSDåå¿œãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰DLç”Ÿæˆãƒ¢ãƒ‡ãƒ«ç”¨ã®åŸ‹ã‚è¾¼ã¿ã¸ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã€‚
        """
        
        # 1. SSDã®åå¿œãƒ™ã‚¯ãƒˆãƒ«ï¼ˆæ¦‚å¿µæ´»æ€§åº¦ã€å±¤ã®åå¿œï¼‰ã‚’PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        concept_features = torch.FloatTensor(reaction.concept_activations)
        layer_features = torch.FloatTensor([
            reaction.layer_responses.get('physical', 0.0),
            reaction.layer_responses.get('base', 0.0), 
            reaction.layer_responses.get('core', 0.0),
            reaction.layer_responses.get('upper', 0.0)
        ])
        
        # 2. ç‰¹å¾´é‡ã‚’çµåˆã—ã¦å˜ä¸€ã®ãƒ™ã‚¯ãƒˆãƒ«ã«ã™ã‚‹
        combined_features = torch.cat([concept_features, layer_features])
        
        # 3. å¤‰æ›ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’é€šã—ã¦ã€DLãƒ¢ãƒ‡ãƒ«ãŒç†è§£ã§ãã‚‹åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
        dl_embedding = self.ssd_to_dl_net(combined_features)
        
        # 4. ã€Œè·³èºã€ã§ç”Ÿã¾ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Œã°ã€ãã‚Œã‚’åŸ‹ã‚è¾¼ã¿ã«åæ˜ ã•ã›ã‚‹
        if reaction.emergent_keywords:
            keyword_adjustment = self._compute_keyword_adjustment(
                reaction.emergent_keywords
            )
            # ãƒ™ã‚¯ãƒˆãƒ«ã‚’å¾®èª¿æ•´ã—ã¦ã€å‰µç™ºçš„ãªãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚’åŠ ãˆã‚‹
            dl_embedding = dl_embedding + keyword_adjustment
            
        return dl_embedding

    # --- è£œåŠ©ãƒ¡ã‚½ãƒƒãƒ‰ ---

    def _labels_to_layer_pressures(self, labels: List[SSDLabel]) -> Dict[str, np.ndarray]:
        """æŠ½å‡ºã—ãŸãƒ©ãƒ™ãƒ«æƒ…å ±ã‹ã‚‰ã€å„å±¤ã¸ã®æ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹"""
        layer_pressures = {
            'physical': np.zeros(self.layer_dim),
            'base': np.zeros(self.layer_dim * 2),
            'core': np.zeros(self.layer_dim * 2), 
            'upper': np.zeros(self.layer_dim)
        }
        
        for label in labels:
            layer_key = label.layer.value.lower()
            if layer_key not in layer_pressures: continue
                
            # æ¦‚å¿µã®ç¨®é¡ã«å¿œã˜ã¦ã€ãƒ™ã‚¯ãƒˆãƒ«ã®ç‰¹å®šã®ä½ç½®ã‚’æ´»æ€§åŒ–ã•ã›ã‚‹
            concept_dim_index = self._concept_to_dimension(label.concept)
            activation_strength = label.confidence
            
            target_vector = layer_pressures[layer_key]
            if concept_dim_index < len(target_vector):
                target_vector[concept_dim_index] += activation_strength
        
        return layer_pressures

    def _concept_to_dimension(self, concept: SSConcept) -> int:
        """æ¦‚å¿µEnumã‚’ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        concept_hash = hash(concept.value)
        # ç°¡æ˜“çš„ã«ãƒãƒƒã‚·ãƒ¥å€¤ã‚’ä½¿ã£ã¦ã„ã‚‹ãŒã€æœ¬æ¥ã¯å­¦ç¿’å¯èƒ½ãªãƒãƒƒãƒ”ãƒ³ã‚°ãŒæœ›ã¾ã—ã„
        return concept_hash % (self.layer_dim * 2) # æœ€å¤§ã®æ¬¡å…ƒæ•°ã§å‰²ã‚‹

    def _integrate_dl_embedding(self, 
                                layer_pressures: Dict[str, np.ndarray],
                                dl_embedding: torch.Tensor) -> Dict[str, np.ndarray]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®åœ§åŠ›ã¨ã€DLåŸ‹ã‚è¾¼ã¿ã‹ã‚‰ã®å°„å½±ã‚’çµ±åˆã™ã‚‹"""
        with torch.no_grad():
            # DLåŸ‹ã‚è¾¼ã¿ã‚’å„å±¤ã®æ¬¡å…ƒç©ºé–“ã«å°„å½±
            projections = {
                'physical': self.dl_to_ssd_net['physical_projector'](dl_embedding).numpy(),
                'base': self.dl_to_ssd_net['base_projector'](dl_embedding).numpy(),
                'core': self.dl_to_ssd_net['core_projector'](dl_embedding).numpy(),
                'upper': self.dl_to_ssd_net['upper_projector'](dl_embedding).numpy()
            }
            
            # ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®åœ§åŠ›ã¨DLåŸ‹ã‚è¾¼ã¿ã‹ã‚‰ã®åœ§åŠ›ã‚’é‡ã¿ä»˜ãã§åŠ ç®—
            alpha = 0.6  # ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®ä¿¡é ¼åº¦
            beta = 0.4   # DLåŸ‹ã‚è¾¼ã¿ã®ä¿¡é ¼åº¦
            
            enhanced = {
                layer: alpha * layer_pressures[layer] + beta * projections[layer]
                for layer in layer_pressures
            }
        return enhanced

    def _compute_keyword_adjustment(self, keywords: List[str]) -> torch.Tensor:
        """å‰µç™ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰åŸ‹ã‚è¾¼ã¿ã®èª¿æ•´ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        adjustment = torch.zeros(self.embedding_dim)
        for keyword in keywords:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒãƒƒã‚·ãƒ¥ã‚’ä½¿ã„ã€æ±ºå®šè«–çš„ã ãŒäºˆæ¸¬ä¸èƒ½ãªèª¿æ•´ã‚’åŠ ãˆã‚‹
            hash_val = hash(keyword)
            torch.manual_seed(hash_val)
            adjustment += torch.randn(self.embedding_dim) * 0.05
        return adjustment

    def create_prompt_from_reaction(self, reaction: ReactionVector) -> str:
        """SSDåå¿œã‹ã‚‰ã€ãƒ‡ãƒãƒƒã‚°ã‚„LLMã¸ã®æŒ‡ç¤ºã«ä½¿ãˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
        
        # æœ€ã‚‚æ´»æ€§åŒ–ã—ãŸæ¦‚å¿µã‚’ç‰¹å®š
        top_concepts = []
        if len(reaction.concept_activations) > 0:
            # æ¦‚å¿µãƒãƒƒãƒ”ãƒ³ã‚°ã‹ã‚‰é€†å¼•ã
            reverse_mapping = {v: k for k, v in self.concept_mapping.items()}
            top_indices = np.argsort(reaction.concept_activations)[-3:] # ä¸Šä½3ã¤
            top_concepts = [reverse_mapping.get(i, f"unknown_concept_{i}") for i in top_indices]

        # æœ€ã‚‚åå¿œãŒå¼·ã‹ã£ãŸå±¤ã‚’ç‰¹å®š
        dominant_layer = max(reaction.layer_responses.items(), key=lambda item: item[1])[0]

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦ã‚‹
        prompt = f"æ€è€ƒçµæœã®è¦ç´„:\n"
        prompt += f"- ä¸»è¦ãªè¦–ç‚¹: {dominant_layer.upper()}å±¤ã‹ã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n"
        if top_concepts:
            prompt += f"- æ ¸å¿ƒã‚³ãƒ³ã‚»ãƒ—ãƒˆ: {', '.join(reversed(top_concepts))}\n"
        if reaction.emergent_keywords:
            prompt += f"- å‰µç™ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(reaction.emergent_keywords)} (ã“ã‚ŒãŒè·³èºã®çµæœã§ã™)\n"
        prompt += f"- ç¢ºä¿¡åº¦: {reaction.confidence:.0%}\n"
        prompt += "ä¸Šè¨˜ã‚’åŸºã«ã€å‰µé€ çš„ã‹ã¤ä¸€è²«æ€§ã®ã‚ã‚‹å¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        
        return prompt

# --- ãƒ‡ãƒ¢ç”¨é–¢æ•° ---

def dummy_ssd_core(pressure: MeaningPressureVector) -> ReactionVector:
    """
    SSDã‚³ã‚¢ã®å‹•ä½œã‚’æ¨¡æ“¬ã™ã‚‹ãƒ€ãƒŸãƒ¼é–¢æ•°ã€‚
    å…¥åŠ›ã•ã‚ŒãŸæ„å‘³åœ§ã«å¿œã˜ã¦ã€ã‚‚ã£ã¨ã‚‚ã‚‰ã—ã„åå¿œãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    # ã©ã®å±¤ãŒæœ€ã‚‚å¼·ãåˆºæ¿€ã•ã‚ŒãŸã‹ã‚’è¨ˆç®—
    layer_means = {
        'physical': np.mean(np.abs(pressure.physical)),
        'base': np.mean(np.abs(pressure.base)),
        'core': np.mean(np.abs(pressure.core)),
        'upper': np.mean(np.abs(pressure.upper))
    }
    dominant_layer = max(layer_means.items(), key=lambda item: item[1])[0]

    # ãƒ€ãƒŸãƒ¼ã®åå¿œã‚’ç”Ÿæˆ
    concept_activations = np.random.rand(1000) # 1000ãƒãƒ¼ãƒ‰
    if dominant_layer == 'upper':
        # ä¸Šå±¤ãŒåˆºæ¿€ã•ã‚ŒãŸã‚‰ã€Œè·³èºã€ã‚„ã€Œä¾¡å€¤è¦³ã€ã«é–¢é€£ã™ã‚‹ãƒãƒ¼ãƒ‰ã‚’æ´»æ€§åŒ–
        concept_activations[hash(SSConcept.JUMP.value) % 1000] = 0.9
        concept_activations[hash("ä¾¡å€¤è¦³") % 1000] = 0.85
    elif dominant_layer == 'base':
        # åŸºå±¤ãªã‚‰ã€Œæ„å‘³åœ§ã€ã€Œæ„Ÿæƒ…ã€
        concept_activations[hash(SSConcept.MEANING_PRESSURE.value) % 1000] = 0.9
        concept_activations[hash("æ„Ÿæƒ…") % 1000] = 0.8
        
    return ReactionVector(
        concept_activations=concept_activations,
        layer_responses=layer_means,
        emergent_keywords=["ç™ºè¦‹", "å†æ§‹ç¯‰"] if dominant_layer == 'upper' else [],
        confidence=np.random.uniform(0.6, 0.9)
    )


def demo_bridge():
    """ãƒ–ãƒªãƒƒã‚¸ã®å‹•ä½œãƒ‡ãƒ¢"""
    bridge = SSDBridge(concept_nodes=len(SimpleSSDLabelingEngine()._build_keyword_map()) + 20) # ãƒãƒƒãƒ”ãƒ³ã‚°ã«åˆã‚ã›ã¦èª¿æ•´
    
    test_cases = [
        "ä¸Šå¸ã‹ã‚‰ã®ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãŒå¼·ãã¦ã€ã‚‚ã†é™ç•Œã ã€‚ã‚¹ãƒˆãƒ¬ã‚¹ã§ä½•ã‚‚æ‰‹ã«ã¤ã‹ãªã„ã€‚",
        "æ¯æ—¥åŒã˜ã“ã¨ã®ç¹°ã‚Šè¿”ã—ã§é£½ããŸã€‚ä½•ã‹æ–°ã—ã„æŒ‘æˆ¦ãŒã—ãŸã„ã€‚",
        "çªç„¶ã€å…¨ã¦ãŒç¹‹ãŒã‚‹ã‚ˆã†ãªæœ€é«˜ã®ã‚¢ã‚¤ãƒ‡ã‚¢ãŒé–ƒã„ãŸï¼ã“ã‚Œã¯é©å‘½ã«ãªã‚‹ï¼",
        "ä¼šç¤¾ã®ãƒ«ãƒ¼ãƒ«ã¨ã€è‡ªåˆ†ãŒå¤§åˆ‡ã«ã—ã¦ã„ã‚‹ä¾¡å€¤è¦³ãŒã©ã†ã—ã¦ã‚‚åˆã‚ãªã„ã€‚"
    ]
    
    print("=== SSDæ„å‘³ãƒ–ãƒªãƒƒã‚¸ ãƒ‡ãƒ¢ ===\n")
    
    for i, text in enumerate(test_cases, 1):
        print(f"--- ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i} ---")
        print(f"ğŸ‘¤ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: ã€Œ{text}ã€")
        
        # 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ (ãƒ†ã‚­ã‚¹ãƒˆ â†’ SSDæ„å‘³åœ§)
        # å¤–éƒ¨DLãƒ¢ãƒ‡ãƒ«ãŒãªã„ãŸã‚ã€dl_embeddingã¯Noneã¨ã™ã‚‹
        meaning_pressure = bridge.encode_to_ssd(text, dl_embedding=None)
        
        print(f"\nğŸ“¥ [ãƒ–ãƒªãƒƒã‚¸/å…¥åŠ›å±¤] ãƒ†ã‚­ã‚¹ãƒˆã‚’SSDæ„å‘³åœ§ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã—ã¾ã—ãŸ:")
        print(f"  - æ¤œå‡ºã•ã‚ŒãŸä¸»è¦æ¦‚å¿µ: {[l['concept'] for l in meaning_pressure.metadata['detected_labels']]}")
        print(f"  - æœ€ã‚‚é–¢é€£ã™ã‚‹å±¤: {max(meaning_pressure.metadata['layer_activation_summary'].items(), key=lambda x:x[1])[0]}")

        # 2. æ¨¡æ“¬SSDã‚³ã‚¢ã§ã®å‡¦ç†
        reaction = dummy_ssd_core(meaning_pressure)
        print("\nğŸ§  [æ¨¡æ“¬SSDã‚³ã‚¢] æ„å‘³åœ§ã‚’å‡¦ç†ã—ã€åå¿œãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")

        # 3. ãƒ‡ã‚³ãƒ¼ãƒ‰ (SSDåå¿œ â†’ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ)
        prompt_for_llm = bridge.create_prompt_from_reaction(reaction)
        
        print(f"\nğŸ“¤ [ãƒ–ãƒªãƒƒã‚¸/å‡ºåŠ›å±¤] åå¿œãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰ç”ŸæˆAIç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ:")
        print("--------------------------------------------------")
        print(prompt_for_llm)
        print("--------------------------------------------------")

        print("\n" + "="*60 + "\n")

if __name__ == "__main__":
    demo_bridge()
